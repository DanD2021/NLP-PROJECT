% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

% Yin24: Directly investigate the research question, shows emperical 
% effect and also addresses cross-cultural (lingual) differences.
@article{yin24-should-respect,
    author      = {Yin, Ziqi and Wang, Hao and Horio, Kaito and Kawahara, Daisuke and Sekine, Satoshi},
    title       = {Should We Respect {LLMs}? A Cross-Lingual Study on the Influence of Prompt Politeness on {LLM} Performance},
    journal     = {Computing Research Repository},
    volume      = {arXiv:2402.14531},
    year        = {2024},
    url         = {https://arxiv.org/abs/2402.14531},
    note        = {version 2}
}

% Li23: Focuses on using LMs to understand (i.e., predict) politeness.
% These are shown to better than classical methods, but a gap to some
% extent is also visible, suggesting human-hand is needed for large-
% and quality-scale survey of our kind.
@inproceedings{li23-how-understand,
  author        = {Li, Can and Pang, Bin and Wang, Wenbo and Hu, Lingshu and Gordon, Matthew and Marinova, Detelina and Balducci, Bitty and Shang, Yi},
  booktitle     = {2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title         = {How Well Can Language Models Understand Politeness?}, 
  year          = {2023},
  volume        = {},
  number        = {},
  pages         = {230-231},
  keywords      = {Computational modeling;Bit error rate;Encyclopedias;Predictive models;Linguistics;Chatbots;Data models;BERT;ChatGPT;Large Language Model (LLM);Politeness Prediction},
  doi           = {10.1109/CAI54212.2023.00106}
}

% Okoso24: focuses on the effects of tone (among many others, the 
% level of politeness) of the machine, not the user - in recommender 
% systems.
@inproceedings{okoso24-tone-recommenders,
  author        = {Okoso, Ayano and Otaki, Keisuke and Koide, Satoshi and Baba, Yukino}, 
  booktitle     = {Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
  title         = {Toward Tone-Aware Explanations in Recommender Systems}, 
  year          = {2024},
  isbn          = {9798400704338},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  doi           = {10.1145/3627043.3659572},
  location      = {Cagliari, Italy},
  numpages      = {6},
  pages         = {261–266},
  keywords      = {Explanations, Tone},
}

% Schmidt24: about prompt engineering, and the need for a systematic,
% disciplined approach for that purpose, that guides both the users'
% interaction with the LLM and its evaluation.
@article{schmidt24-prompt-catalog,
  author        = {Schmidt, Douglas C. and Spencer-Smith, Jesse and Fu, Quchen and White, Jules}, 
  title         = {Towards a Catalog of Prompt Patterns to Enhance the Discipline of Prompt Engineering}, 
  booktitle     = {Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
  year          = {2024},
  issue_date    = {December 2023},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {43},
  number        = {2},
  issn          = {1094-3641},
  doi           = {10.1145/3672359.3672364},
  journal       = {Ada Lett.},
  month         = jun,
  pages         = {43–51},
  numpages      = {9}
}

% Sahoo24: provides a taxonomy of prompt engineering tehcniques, with
% a minor saying regarding the impact of tone and emotion in the 
% prompts.
@article{sahoo24-prompt-survey,
    author      = {Sahoo, Pranab and Singh, Ayush Kumar and Saha, Sriparna and Jain, Vinija and Mondal, Samrat and Chadha, Aman},
    title       = {A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
    journal     = {Computing Research Repository},
    volume      = {arXiv:2402.07927},
    year        = {2024},
    url         = {https://arxiv.org/abs/2402.07927},
    note        = {version 1}
}

% Lee24: The idea of using LLMs (ChatGPT specifically) for AI-assited
% pragmatics instruction is investigated (based on the notion 
% pragmatics is an important language feature often not addressed
% appropriately). Difficulty by the LLM to phrase apologies, 
% particularly w.r.t. their politeness, is noted.
@article{lee24-potential-pragmatics,
    title       = {Exploring the potential of {AI} for pragmatics instruction},
    author      = {Lee, Bradford J. and Daniel R., Cook},
    year        = {2024},
    month       = {Oct.}, 
    volume      = {6},
    url         = {https://www.castledown.com/journals/tltl/article/view/tltl.v6n3.1521},
    doi         = {10.29140/tltl.v6n3.1521},
    number      = {3},
    journal     = {Technology in Language Teaching \& Learning},
    pages={1521}
}

% Joel24: The phrasing of LLMs' denials and its effects on the users
% is investigated; politeness is one of the relevant factors 
% considered.
@inproceedings{joel24-llm-denials,
    author      = {Wester, Joel and Schrills, Tim and Pohl, Henning and van Berkel, Niels},
    title       = {``{A}s an {AI} language model, {I} cannot'': Investigating {LLM} Denials of User Requests},
    year        = {2024},
    isbn        = {9798400703300},
    publisher   = {Association for Computing Machinery},
    address     = {New York, NY, USA},
    doi         = {10.1145/3613904.3642135},
    booktitle   = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
    articleno   = {979},
    numpages    = {14},
    keywords    = {Breakdowns, Denials, Errors, GPT-4, Large Language Models},
    location    = {Honolulu, HI, USA},
    series      = {CHI '24}
}

% Bommasani22: comprehensive review of foundation and large language
% models.
@article{bommasani22-foundation-models,
    author      = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
    title       = {On the Opportunities and Risks of Foundation Models},
    journal     = {Computing Research Repository},
    volume      = {arXiv:2108.07258},
    year        = {2022},
    url         = {https://arxiv.org/abs/2108.07258},
    note        = {version 3}
}

% Zellers18: introduces the reading comprehension SWAG dataset.
@article{zellers18-swag,
    author      = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
    title       = {{SWAG}: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference},
    journal     = {Computing Research Repository},
    volume      = {arXiv:1808.05326},
    year        = {2018},
    url         = {https://arxiv.org/abs/1808.05326},
    note        = {version 1}
}
